import pandas as pdimport numpy as npimport kerasimport os from glob import  globfrom scipy import ndimage as ndimport torchfrom torch.utils.data import Dataset, DataLoaderimport torchvisionfrom sklearn.model_selection import train_test_splitfrom torch import nnimport torch.nn.functional as Ffrom sklearn.metrics import confusion_matrix , classification_report , roc_curve ,aucimport matplotlib.pyplot as pltimport seaborn as snsfrom sklearn.metrics import confusion_matrix , classification_report ,cohen_kappa_score ,recall_score ,f1_score ,precision_score signal_file_name="amygdala"epochs=15batch_size=8res_path=f"./model_result/{signal_file_name}"checkpoint_path=f"./model_result/{signal_file_name}/checkpoint"os.makedirs(res_path,exist_ok=True)imp_path=f"./resnet_res/{signal_file_name}"datapath=glob(f"{imp_path}/*.pt")df=pd.DataFrame(datapath,columns=["path"])df["label"]=df["path"].apply(lambda x :int(x[-4]))# del datapathclass customDataset (Dataset):    def __init__(self,path_df):        self.df=path_df                def __len__(self):        return(len(self.df))        def __getitem__(self,index):        path,lbl=self.df.iloc[index]        mri=torch.load(path)        mri=torch.tensor(mri,dtype=torch.float)        return(mri,lbl)         train_df,test_df=train_test_split(df,test_size=.4)trainset = customDataset(train_df)testset = customDataset(test_df)train_loader = DataLoader(trainset,batch_size=batch_size)  x,y=trainset.__getitem__(10)   class custom_model(nn.Module):    def __init__(self):        super(custom_model,self).__init__()        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=2)        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, padding=2)        self.conv23=nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, padding=1)                    self.conv3 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=2)        self.conv4 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=2)        self.conv5 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)        self.bn1 = nn.BatchNorm2d(4)        self.bn2 = nn.BatchNorm2d(8)        self.bn3 = nn.BatchNorm2d(16)        self.bn4 = nn.BatchNorm2d(32)        self.bn5 = nn.BatchNorm2d(64)        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)        self.avg = nn.AvgPool2d(5)        self.lstm1 = nn.LSTM(50,30,2, batch_first=True)        self.lstm2 = nn.LSTM(30,10,1, batch_first=True)        self.fc1 = nn.Linear(3840, 64)        self.fc2 = nn.Linear(64, 1) # !!!            def forward(self, x_input):        x_lst=[]        for x in x_input:            x = torch.unsqueeze(x,1)            x = self.pool(F.leaky_relu(self.bn1(self.conv1(x)))) # first convolutional layer then batchnorm, then activation then pooling layer.            x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))            dx= F.leaky_relu(self.bn2(self.conv23(x)))            x=x+dx            x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))            x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))            x = self.pool(F.leaky_relu(self.bn5(self.conv5(x))))            x = self.avg(x)            x = x.view(-1, 64 * 1 * 6) # !!!            x = torch.unsqueeze(x,0)            x_lst.append(x)        x=torch.cat(x_lst)         del x_lst        x = torch.permute(x,[0,2,1])        x,_ = self.lstm1(x)        x,_ = self.lstm2(x)        x = nn.Flatten()(x)        x = F.relu(self.fc1(x))        x = torch.sigmoid(self.fc2(x))        x=torch.squeeze(x)        return x    model=custom_model()critrion=nn.BCELoss()optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)total_step=len(train_loader)val_loss_hist=[]val_acc_hist=[]for epoch in range (1,epochs+1):    for step,(x_train,lbl_train) in enumerate(train_loader):        train_pred=model(x_train.float())        loss=critrion(train_pred,lbl_train.float())        optimizer.zero_grad()        loss.backward()        optimizer.step()        pred=torch.round(train_pred)        correct = (pred == lbl_train).sum().item()        acc=100*(correct/len(train_pred))        if (step+1) % 1 == 0:            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} , accuracy: {:.2f}'                     .format(epoch+1, epochs+1, step+1, total_step, loss.item(),acc))            print(confusion_matrix(lbl_train.detach().numpy(),pred.detach().numpy()))                if step == total_step-1:                    test_pred_lst=[]            test_lbl_lst=[]            for i in range (testset.__len__()):                img,lbl=testset.__getitem__(i)                img=torch.unsqueeze(img,0)                test_pred=model(img.float())                test_pred_lst.append(test_pred)                test_lbl_lst.append(lbl)                            test_pred_lst=torch.hstack(test_pred_lst)            test_lbl_lst=torch.tensor(test_lbl_lst,dtype=torch.float)                        val_loss=critrion(test_pred_lst,test_lbl_lst)                 val_pred=torch.round(test_pred_lst)            val_correct = (val_pred == test_lbl_lst).sum().item()                val_acc=100*(val_correct/len(test_lbl_lst))            val_acc_hist.append(val_acc)            val_loss_hist.append(val_loss)torch.save(model,f"./{checkpoint_path}/model.pth")    test_pred_lst=[]test_lbl_lst=[]for i in range (testset.__len__()):    img,lbl=testset.__getitem__(i)    img=torch.unsqueeze(img,0)    test_pred=model(img.float())    test_pred_lst.append(test_pred)    test_lbl_lst.append(lbl)    test_pred_lst=torch.hstack(test_pred_lst)test_lbl_lst=torch.tensor(test_lbl_lst,dtype=torch.float)loss=critrion(test_pred_lst,test_lbl_lst) pred=torch.round(test_pred_lst)correct = (pred == test_lbl_lst).sum().item()acc=100*(correct/len(test_lbl_lst))print ('Loss: {:.4f} , accuracy: {:.2f}'         .format(loss.item(),acc))true_lst=test_lbl_lst.detach().numpy()pred_lst=pred.detach().numpy()print(confusion_matrix(true_lst,pred_lst))print(classification_report(true_lst,pred_lst))def plot_confusion_matrix(true,pred,f_name=None):    fig,ax=plt.subplots(figsize = (9,7))    sns.heatmap(confusion_matrix(true,pred),                yticklabels=["unhealthy","healthy"],                xticklabels=["unhealthy","healthy"],                 annot=True, fmt='d')    ax.set_xlabel('Predicted')    ax.set_ylabel('Truth')    fig.show()    if f_name:        fig.savefig(f_name,dpi=600)    plot_confusion_matrix(true_lst,pred_lst,f"{res_path}/Confusion_matrix.jpg")# plot ROC curvey_score =np.array(test_pred_lst.detach().numpy())fpr, tpr, thresholds = roc_curve(np.array(true_lst), y_score)roc_auc = auc(fpr, tpr)plt.title('Receiver Operating Characteristic')plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc ,linewidth=3)plt.legend(loc = 'lower right')plt.plot([0, 1], [0, 1],'r--')plt.xlim([0, 1])plt.ylim([0, 1])plt.ylabel('True Positive Rate')plt.xlabel('False Positive Rate')plt.savefig(f"{res_path}/ROC_Curve.jpg",dpi=600)res_file=open(f"{res_path}/result.txt","w+")res_file.write(f"classification report for {signal_file_name}\n")res_file.write(f"kappa score : {cohen_kappa_score(true_lst,pred_lst)}\n")res_file.write(f"recall score : {recall_score(true_lst,pred_lst,average= 'macro')}\n")res_file.write(f"f1 score : {f1_score(true_lst,pred_lst,average= 'macro')}\n")res_file.write(f"precision score : {precision_score(true_lst,pred_lst,average= 'macro')}\n")res_file.write(classification_report(true_lst,pred_lst))res_file.close()